{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b405616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D, BatchNormalization\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6767c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/leapGestRecog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c785aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "for directory in os.listdir(dir):\n",
    "  for subDir in os.listdir(os.path.join(dir,directory)):\n",
    "    for img in os.listdir(os.path.join(dir, directory, subDir)):\n",
    "      img_path = os.path.join(dir, directory, subDir, img)\n",
    "      images.append(img_path)\n",
    "      labels.append(subDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfce788",
   "metadata": {},
   "outputs": [],
   "source": [
    "Iseries = pd.Series(images, name=\"Images\")\n",
    "Lseries = pd.Series(labels, name=\"labels\")\n",
    "hand_gesture_data = pd.concat([Iseries, Lseries], axis=1)\n",
    "hand_gesture_df = pd.DataFrame(hand_gesture_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daacaaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(hand_gesture_df, test_size=0.2, random_state=42)\n",
    "train_set, val_set = train_test_split(hand_gesture_df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dfaf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(preprocessing_function= tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "train = image_gen.flow_from_dataframe(dataframe= train_set,x_col=\"Images\",y_col=\"labels\",\n",
    "                                      target_size=(244,244),\n",
    "                                      color_mode='rgb',\n",
    "                                      class_mode=\"categorical\",\n",
    "                                      batch_size=4,\n",
    "                                      shuffle=False\n",
    "                                     )\n",
    "test = image_gen.flow_from_dataframe(dataframe= X_test,x_col=\"Images\", y_col=\"labels\",\n",
    "                                     target_size=(244,244),\n",
    "                                     color_mode='rgb',\n",
    "                                     class_mode=\"categorical\",\n",
    "                                     batch_size=4,\n",
    "                                     shuffle= False\n",
    "                                    )\n",
    "val = image_gen.flow_from_dataframe(dataframe= val_set,x_col=\"Images\", y_col=\"labels\",\n",
    "                                    target_size=(244,244),\n",
    "                                    color_mode= 'rgb',\n",
    "                                    class_mode=\"categorical\",\n",
    "                                    batch_size=4,\n",
    "                                    shuffle=False\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b6834f",
   "metadata": {},
   "source": [
    "Found 14000 validated image filenames belonging to 10 classes.\n",
    "\n",
    "Found 4000 validated image filenames belonging to 10 classes.\n",
    "\n",
    "Found 6000 validated image filenames belonging to 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eb0608",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=list(train.class_indices.keys())\n",
    "print (classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56bd80",
   "metadata": {},
   "source": [
    "['01_palm', '02_l', '03_fist', '04_fist_moved', '05_thumb', '06_index', '07_ok', '08_palm_moved', '09_c', '10_down']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_hand_gesture(image_gen):\n",
    "    test_dict = test.class_indices\n",
    "    classes = list(test_dict.keys())\n",
    "    images, labels=next(image_gen)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    length = len(labels)\n",
    "    if length<25:\n",
    "        r=length\n",
    "    else:\n",
    "        r=25\n",
    "    for i in range(r):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        image=(images[i]+1)/2\n",
    "        plt.imshow(image)\n",
    "        index=np.argmax(labels[i])\n",
    "        class_name=classes[index]\n",
    "        plt.title(class_name, color=\"green\",fontsize=16)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "show_hand_gesture(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2350dff",
   "metadata": {},
   "outputs": [],
   "source": [
    " model = Sequential([\n",
    "    Conv2D(filters=128, kernel_size=(8, 8), strides=(3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3, 3)),\n",
    "\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=256, kernel_size=(1, 1), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=256, kernel_size=(1, 1), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.optimizers.SGD(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbf21a1",
   "metadata": {},
   "source": [
    "Model: \"sequential_2\"\n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    " Layer (type)                Output Shape              Param #   \n",
    "\n",
    "=================================================================\n",
    "\n",
    " conv2d_18 (Conv2D)          (None, 73, 73, 128)       24704     \n",
    "\n",
    "                                                                 \n",
    "\n",
    " batch_normalization_18 (Ba  (None, 73, 73, 128)       512       \n",
    "\n",
    " tchNormalization)                                               \n",
    "\n",
    "                                                                 \n",
    "\n",
    " conv2d_19 (Conv2D)          (None, 73, 73, 256)       819456    \n",
    "\n",
    "                                                                 \n",
    "\n",
    " batch_normalization_19 (Ba  (None, 73, 73, 256)       1024      \n",
    "\n",
    " tchNormalization)                                               \n",
    "\n",
    "                                                                 \n",
    "\n",
    " max_pooling2d_8 (MaxPoolin  (None, 24, 24, 256)       0         \n",
    "\n",
    " g2D)                                                            \n",
    "\n",
    "                                                                 \n",
    "\n",
    " conv2d_20 (Conv2D)          (None, 24, 24, 256)       590080    \n",
    "\n",
    "                                                                 \n",
    "\n",
    " batch_normalization_20 (Ba  (None, 24, 24, 256)       1024      \n",
    "\n",
    " tchNormalization)                                               \n",
    "\n",
    "                                                                 \n",
    "\n",
    " conv2d_21 (Conv2D)          (None, 24, 24, 256)       65792     \n",
    "\n",
    "                                                                 \n",
    "\n",
    " batch_normalization_21 (Ba  (None, 24, 24, 256)       1024      \n",
    "\n",
    " tchNormalization)                                               \n",
    "\n",
    "                                                                 \n",
    "\n",
    " conv2d_22 (Conv2D)          (None, 24, 24, 256)       65792     \n",
    "\n",
    "                                                                 \n",
    "\n",
    " batch_normalization_22 (Ba  (None, 24, 24, 256)       1024      \n",
    "\n",
    " tchNormalization)                                               \n",
    "\n",
    "                                                                 \n",
    "\n",
    " conv2d_23 (Conv2D)          (None, 24, 24, 512)       1180160   \n",
    "\n",
    "                                                                 \n",
    "\n",
    " batch_normalization_23 (Ba  (None, 24, 24, 512)       2048      \n",
    "\n",
    " tchNormalization)                                               \n",
    "\n",
    "                                                                 \n",
    "\n",
    " max_pooling2d_9 (MaxPoolin  (None, 12, 12, 512)       0         \n",
    "\n",
    " g2D)                                                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b837f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "\n",
    "labels = (train.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred2 = [labels[k] for k in pred]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7adbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "y_test = X_test.labels\n",
    "print(classification_report(y_test, pred2))\n",
    "print(\"Accuracy of the Model:\",\"{:.1f}%\".format(accuracy_score(y_test, pred2)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eef063",
   "metadata": {},
   "source": [
    "        precision    recall  f1-score   support\n",
    "\n",
    "\n",
    "\n",
    "      01_palm       1.00      1.00      1.00       404\n",
    "\n",
    "         02_l       1.00      1.00      1.00       377\n",
    "\n",
    "      03_fist       1.00      1.00      1.00       404\n",
    "\n",
    "04_fist_moved       1.00      1.00      1.00       410\n",
    "\n",
    "     05_thumb       1.00      1.00      1.00       417\n",
    "\n",
    "     06_index       1.00      1.00      1.00       366\n",
    "\n",
    "        07_ok       1.00      1.00      1.00       418\n",
    "\n",
    "08_palm_moved       1.00      1.00      1.00       403\n",
    "\n",
    "         09_c       1.00      1.00      1.00       392\n",
    "\n",
    "      10_down       1.00      1.00      1.00       409\n",
    "\n",
    "\n",
    "\n",
    "     accuracy                           1.00      4000\n",
    "\n",
    "    macro avg       1.00      1.00      1.00      4000\n",
    "\n",
    " weighted avg       1.00      1.00      1.00      4000\n",
    "\n",
    "\n",
    "\n",
    "Accuracy of the Model: 100.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31905f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
